{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(config.data)\n",
    "lst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_motif_page_correct(soup):\n",
    "    list_of_regions = []\n",
    "    list_of_nations = []\n",
    "    list_of_texts = []\n",
    "    list_of_codenames = []\n",
    "    list_of_motifs = []\n",
    "    \n",
    "    try:\n",
    "        code_name = soup.findAll(\"p\", {\"class\": \"NormalLin\"})[0].get_text()\n",
    "    except AttributeError:\n",
    "        code_name = '-'\n",
    "    except IndexError:\n",
    "        code_name = '-'\n",
    "        \n",
    "    try:\n",
    "        motif = soup.findAll(\"p\", {\"class\": \"NormalLis\"})[0].get_text()\n",
    "    except AttributeError:\n",
    "        motif = '-'\n",
    "    except IndexError:\n",
    "        motif = '-'\n",
    "\n",
    "    for region in soup.findAll(\"p\", {\"class\": \"NormalMai\"}):\n",
    "        try:\n",
    "            reg = region.find(\"b\").get_text()\n",
    "            for nation in region.findAll(\"u\"):\n",
    "                list_of_regions.append(reg)\n",
    "                list_of_nations.append(nation.get_text())\n",
    "                list_of_texts.append(region)\n",
    "                list_of_codenames.append(code_name)\n",
    "                list_of_motifs.append(motif)\n",
    "        except AttributeError:\n",
    "#             print('except in find B: {}'.format(code_name))\n",
    "            pass\n",
    "            \n",
    "    myth_df = pd.DataFrame(data={'region': list_of_regions, \n",
    "                                 'nation':list_of_nations, \n",
    "                                 'text': list_of_texts,\n",
    "                                 'code_name':list_of_codenames, \n",
    "                                 'motif': list_of_motifs})\n",
    "            \n",
    "    return myth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "for file in tqdm(lst, total = len(lst)):\n",
    "    with open('../data/myths/{}'.format(file), 'rb') as html:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        tmp_df = parse_motif_page_correct(soup)\n",
    "        final_df = pd.concat([final_df, tmp_df])\n",
    "        \n",
    "final_df.nation.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "достаем код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['code_true'] = final_df['code_name'].apply(lambda x: x.split(' ')[0].replace('.', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "местами неправильная кодировка, делаю правильную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'РњРµР·РѕР°РјРµСЂРёРєР°.'.encode(\"windows-1251\").decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_only_decoded(x):\n",
    "    try:\n",
    "        return x.encode(\"windows-1251\").decode(\"utf-8\")\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['region'] = final_df['region'].progress_apply(lambda x: encode_only_decoded(x))\n",
    "final_df['nation'] = final_df['nation'].progress_apply(lambda x: encode_only_decoded(x))\n",
    "final_df['text'] = final_df['text'].progress_apply(lambda x: encode_only_decoded(x))\n",
    "final_df['code_name'] = final_df['code_name'].progress_apply(lambda x: encode_only_decoded(x))\n",
    "final_df['motif'] = final_df['motif'].progress_apply(lambda x: encode_only_decoded(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нормальный code name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code_name(x):\n",
    "    return re.sub(r'[^а-яА-Я ]', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['code_name'] = final_df['code_name'].apply(clean_code_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "нормальный текст: изначально в колонке - весь текст по региону, берем только то что после упоминания того народа, который у нас в nation, но до следующего \\<u\\> - подразумевается что там следующий народ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(x):\n",
    "    try:\n",
    "        return str(x['text']).split('<u>{}</u>'.format(x['nation']))[1].split('<u>')[0]\n",
    "    except IndexError:\n",
    "        return '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'] = final_df.apply(lambda x: get_text(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region+nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['region'] = final_df['region'].apply(lambda x: re.sub(r'[^а-яА-Я ]', '', x).lower())\n",
    "final_df['nation'] = final_df['nation'].apply(lambda x: re.sub(r'[^а-яА-Я ]', '', x).lower())\n",
    "\n",
    "#например\n",
    "final_df[final_df.code_true == 'D5'].head(20)# допускаю что ничего ценного в дубликатах текстов нет\n",
    "final_df = final_df.drop_duplicates('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "препроцессить тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# допускаю что ничего ценного в дубликатах текстов нет\n",
    "final_df = final_df.drop_duplicates('text')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess(row):\n",
    "    content = re.sub(\"[^А-Яа-я']+\", ' ', str(row)).lower()\n",
    "    content = list(preprocess_text(x) for x in content.split(' '))\n",
    "    content = [x for x in content if x != '']\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['preprocessed'] = final_df['text'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.iloc[43].preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(config.final_df, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
